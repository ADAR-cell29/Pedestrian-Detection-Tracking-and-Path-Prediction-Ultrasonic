{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "id": "fFRYUtB3QjrV",
        "outputId": "e6a4cb9e-d588-4780-afe3-eb525e4128fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Using 4241 PNGs that match the naming convention; skipped 0 others.\n",
            "\n",
            "Saved 4241 frames to /content/OCCLUSION_FRAMES\n",
            "Centroids CSV → /content/centroids.csv\n",
            "Pedestrian tracks CSV → /content/ped_tracks.csv\n",
            "TestSet1 CSV → /content/TestSet1.csv\n",
            "\n",
            "Wrote video → /content/objects_occluded.mp4 at 4 fps (600x350).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<video controls src=\"/content/objects_occluded.mp4\" width=\"640\"></video>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_d64da4d5-35d8-4f0c-aa51-037e60e60e79\", \"objects_occluded.mp4\", 10434821)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_6f85ef89-21c0-4c6a-b6be-ab048beb9661\", \"centroids.csv\", 570805)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_31b1a3ff-f95a-4322-8284-a7676ec80621\", \"ped_tracks.csv\", 86859)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_03432c86-6825-4dc1-97ca-57c5796623f3\", \"TestSet1.csv\", 88800)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved annotated frames ZIP to Drive → /content/drive/MyDrive/annotated_frames.zip\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_8f9a59d5-0566-4617-95d1-07f07e04be00\", \"annotated_frames.zip\", 30059231)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# === RED objects + proportional occlusion + BLUE pedestrian fixed-annulus tracking\n",
        "#     with in-frame consolidation and multi-ID tracking (delayed numbering)\n",
        "#     + ID protection radius (cap-to-blue near confirmed IDs)\n",
        "# + TestSet2.csv with rows only for IDs that have >=5 valid frames\n",
        "#   Columns: t_ms, id, x, y, vx, vy, v, x_plus_1, y_plus_1\n",
        "#   x_plus_1/y_plus_1 use the SAME ID at t+1.0s (+4 frames); if missing → 'NaN'\n",
        "\n",
        "from google.colab import drive, files\n",
        "import os, re, glob, shutil, csv, zipfile\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.cluster import DBSCAN\n",
        "from IPython.display import HTML, display\n",
        "from collections import defaultdict\n",
        "\n",
        "# ---------- Config ----------\n",
        "drive_src    = '/content/drive/MyDrive/RECORDING'\n",
        "local_src    = '/content/RECORDING_LOCAL'\n",
        "frames_dir   = '/content/OCCLUSION_FRAMES'\n",
        "video_path   = '/content/objects_occluded.mp4'\n",
        "csv_path     = '/content/centroids.csv'      # red objects (with occlusion)\n",
        "tracks_csv   = '/content/ped_tracks.csv'     # legacy tracker csv (kept)\n",
        "testset1_csv = '/content/TestSet1.csv'       # NEW final dataset\n",
        "\n",
        "# Preprocessing\n",
        "blur_sigma_px = 7\n",
        "\n",
        "# DBSCAN (meters)\n",
        "EPS_M          = 0.15\n",
        "MIN_SAMPLES    = 15\n",
        "MIN_OBJ_M_RED  = 0.3\n",
        "MIN_OBJ_M_BLUE = 0.2\n",
        "\n",
        "# Geometry (y increases downward)\n",
        "Y_TOP_M, Y_BOTTOM_M = 0.1, 3.5\n",
        "IGNORE_TOP_M = 1.0\n",
        "\n",
        "# Persistence / display\n",
        "MAX_SCORE_CAP  = 10\n",
        "RED_AT_SCORE   = 5\n",
        "INCR_ON_HIT    = 1\n",
        "DECR_ON_MISS   = 1\n",
        "CLUSTER_USE_VAL_RED = 5\n",
        "BLUE_SCORE_MIN, BLUE_SCORE_MAX = 1, 4   # ONLY pixels with score < 5 are \"blue\"\n",
        "\n",
        "# Cluster-aware dimming\n",
        "ON_FRAC_HOLD   = 0.60\n",
        "\n",
        "# Occlusion\n",
        "OCCLUDED_SKIP_FRAC   = 0.50\n",
        "OCCLUSION_AREA_RATIO = 3.0\n",
        "\n",
        "# --- Radii you can tweak ---\n",
        "ASSOC_MIN_M = 0.00           # allow tiny motion (prevents ID churn when still)\n",
        "ASSOC_MAX_M = 1.20\n",
        "RED_BLUE_SUPPRESS_RADIUS_PX = 20\n",
        "CONSOLIDATION_RADIUS_M      = 1.00\n",
        "ID_PROTECT_RADIUS_M         = 0.50\n",
        "\n",
        "# --- Tracking (blue) ---\n",
        "WARMUP_FRAMES   = 4\n",
        "CONFIRM_HITS    = 2\n",
        "MISS_TOL        = 4\n",
        "DT              = 0.25   # s per frame (=> 250 ms)\n",
        "\n",
        "# Colors (BGR)\n",
        "COL_RED_OBJ_PT  = (0, 0, 255)\n",
        "COL_RED_BBOX    = (0, 255, 0)\n",
        "COL_OCC_BOX     = (255, 255, 0)\n",
        "COL_PED         = (255, 0, 0)            # blue dot\n",
        "COL_PED_TEXT    = (255, 255, 255)        # white text\n",
        "\n",
        "# ---------- Helpers ----------\n",
        "pat_full = re.compile(r'^\\[(\\d{4}-\\d{2}-\\d{2})\\s+(\\d{2})-(\\d{2})-(\\d{2})-(\\d{3})\\]\\.png$')\n",
        "def extract_dt(fname):\n",
        "    m = pat_full.match(fname)\n",
        "    date_str, hh, mm, ss, ms = m.groups()\n",
        "    return datetime.strptime(f'{date_str} {hh}:{mm}:{ss}.{ms}', '%Y-%m-%d %H:%M:%S.%f')\n",
        "\n",
        "def oriented_length_m(points_m):\n",
        "    if points_m.shape[0] < 2: return 0.0\n",
        "    c = points_m.mean(axis=0)\n",
        "    _, _, Vt = np.linalg.svd(points_m - c, full_matrices=False)\n",
        "    axis = Vt[0]\n",
        "    proj = (points_m - c) @ axis\n",
        "    return float(proj.max() - proj.min())\n",
        "\n",
        "def build_color_lut(red_at=5):\n",
        "    lut = np.zeros((red_at+1, 3), dtype=np.uint8)\n",
        "    blue = np.array([255, 0, 0], dtype=np.float32)  # B,G,R\n",
        "    red  = np.array([0, 0, 255], dtype=np.float32)\n",
        "    for s in range(1, red_at+1):\n",
        "        t = (s-1) / max(1, (red_at-1))\n",
        "        lut[s] = np.round(blue*(1-t) + red*t).astype(np.uint8)\n",
        "    return lut\n",
        "\n",
        "def rect_contains(outer, inner):\n",
        "    return (outer[0] <= inner[0] and outer[1] <= inner[1] and\n",
        "            outer[2] >= inner[2] and outer[3] >= inner[3])\n",
        "\n",
        "color_lut = build_color_lut(RED_AT_SCORE)\n",
        "\n",
        "# ---------- Prep input ----------\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "os.makedirs(local_src, exist_ok=True)\n",
        "for f in glob.glob(os.path.join(drive_src, '*.png')):\n",
        "    dst = os.path.join(local_src, os.path.basename(f))\n",
        "    if not os.path.exists(dst):\n",
        "        shutil.copy2(f, dst)\n",
        "\n",
        "# Only keep files that exactly match the timestamped naming convention\n",
        "all_pngs = [f for f in os.listdir(local_src) if f.lower().endswith('.png')]\n",
        "valid_pngs = [f for f in all_pngs if pat_full.match(f)]\n",
        "pngs = sorted(valid_pngs, key=extract_dt)\n",
        "print(f\"Using {len(pngs)} PNGs that match the naming convention; \"\n",
        "      f\"skipped {len(all_pngs) - len(valid_pngs)} others.\")\n",
        "assert pngs, \"No PNGs found that match the [YYYY-MM-DD HH-MM-SS-ms].png pattern.\"\n",
        "\n",
        "# ---------- Init ----------\n",
        "tmp = cv2.imread(os.path.join(local_src, pngs[0]), cv2.IMREAD_GRAYSCALE)\n",
        "H, W = tmp.shape\n",
        "SY = (Y_BOTTOM_M - Y_TOP_M) / float(H)\n",
        "SX = SY  # set SX explicitly if horizontal meters/px differ\n",
        "center_x = int((W - 1) / 2)\n",
        "\n",
        "rows_ignore = int(np.ceil(IGNORE_TOP_M / SY))\n",
        "rows_ignore = max(0, min(H, rows_ignore))\n",
        "\n",
        "score = np.zeros((H, W), dtype=np.int32)\n",
        "prev_clusters_pixels = []  # for cluster-aware dimming\n",
        "\n",
        "os.makedirs(frames_dir, exist_ok=True)\n",
        "\n",
        "# CSVs (red + legacy track)\n",
        "with open(csv_path, 'w', newline='') as fcsv:\n",
        "    writer = csv.writer(fcsv)\n",
        "    writer.writerow(['frame', 'cluster_idx', 'cx_m', 'cy_m', 'cx_px', 'cy_px'])\n",
        "with open(tracks_csv, 'w', newline='') as ft:\n",
        "    tw = csv.writer(ft)\n",
        "    tw.writerow(['frame','track_id','state','cx_m','cy_m','cx_px','cy_px','speed_mps'])\n",
        "\n",
        "# Tracking state (multi-ID). ID assigned only when confirmed.\n",
        "next_track_id = 1\n",
        "tracks = {}  # key -> dict(...). Use internal keys; assign visible 'id' at confirmation.\n",
        "internal_next_key = 1\n",
        "\n",
        "# Suppression kernel\n",
        "kernel_rad = RED_BLUE_SUPPRESS_RADIUS_PX\n",
        "dil_kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (2*kernel_rad+1, 2*kernel_rad+1))\n",
        "\n",
        "# Prev-frame masks for protection exclusion\n",
        "prev_red_bbox_mask = np.zeros((H, W), dtype=bool)\n",
        "prev_occ_mask      = np.zeros((H, W), dtype=bool)\n",
        "\n",
        "# --- Collect per-ID per-frame records for TestSet2, then filter/write at the end ---\n",
        "# Each record: (frame_idx, t_ms, x, y, vx, vy, v)\n",
        "records_by_id = defaultdict(list)\n",
        "\n",
        "# ---------- Process ----------\n",
        "for frame_idx, fname in enumerate(pngs):\n",
        "    gray = cv2.imread(os.path.join(local_src, fname), cv2.IMREAD_GRAYSCALE)\n",
        "    if gray is None:\n",
        "        print(\"Skip unreadable:\", fname); continue\n",
        "\n",
        "    # 1) Blur + Otsu\n",
        "    blurred = cv2.GaussianBlur(gray, (0,0), sigmaX=blur_sigma_px, sigmaY=blur_sigma_px)\n",
        "    _, mask = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "    if rows_ignore > 0: mask[:rows_ignore, :] = 0\n",
        "    detect = (mask > 0)\n",
        "\n",
        "    # Cluster-aware dimming → score update\n",
        "    protected = np.zeros((H, W), dtype=bool)\n",
        "    for (ys_prev, xs_prev) in prev_clusters_pixels:\n",
        "        if ys_prev.size and np.mean(detect[ys_prev, xs_prev]) >= ON_FRAC_HOLD:\n",
        "            protected[ys_prev, xs_prev] = True\n",
        "    score += INCR_ON_HIT * detect.astype(np.int32) - DECR_ON_MISS * ((~detect) & (~protected)).astype(np.int32)\n",
        "    score = np.clip(score, 0, MAX_SCORE_CAP)\n",
        "    if rows_ignore > 0: score[:rows_ignore, :] = 0\n",
        "\n",
        "    # ID protection radius (cap to 4) except inside last frame's red/occ\n",
        "    if tracks:\n",
        "        rad_px = int(max(1, round(ID_PROTECT_RADIUS_M / SY)))\n",
        "        id_protect_mask = np.zeros((H, W), dtype=np.uint8)\n",
        "        for tr in tracks.values():\n",
        "            if tr.get('confirmed', False) and tr.get('last_seen', -999) >= 0 and tr.get('misses', 0) <= MISS_TOL:\n",
        "                cx_px, cy_px = tr['centroid_px']\n",
        "                if 0 <= cx_px < W and 0 <= cy_px < H:\n",
        "                    cv2.circle(id_protect_mask, (int(cx_px), int(cy_px)), rad_px, 1, thickness=-1)\n",
        "        if id_protect_mask.any():\n",
        "            block = (id_protect_mask.astype(bool)) & ~(prev_red_bbox_mask | prev_occ_mask)\n",
        "            score[block] = np.minimum(score[block], RED_AT_SCORE - 1)\n",
        "\n",
        "    # Color base\n",
        "    disp = np.minimum(score, RED_AT_SCORE).astype(np.int32)\n",
        "    base = np.zeros((H, W, 3), dtype=np.uint8); nz = disp > 0\n",
        "    base[nz] = color_lut[disp[nz]]\n",
        "    annotated = base.copy()\n",
        "\n",
        "    # ---------- RED OBJECTS ----------\n",
        "    stable_red = (score >= CLUSTER_USE_VAL_RED)\n",
        "    ys_r, xs_r = np.where(stable_red)\n",
        "    clusters_r = []\n",
        "    if xs_r.size:\n",
        "        x_m_r = (xs_r - center_x) * SX\n",
        "        y_m_r = Y_TOP_M + ys_r * SY\n",
        "        pts_r = np.c_[x_m_r, y_m_r]\n",
        "        db_r = DBSCAN(eps=EPS_M, min_samples=MIN_SAMPLES).fit(pts_r)\n",
        "        labels_r = db_r.labels_; uniq_r = [lab for lab in set(labels_r) if lab != -1]\n",
        "        for lab in uniq_r:\n",
        "            idx = np.where(labels_r == lab)[0]\n",
        "            if oriented_length_m(pts_r[idx]) < MIN_OBJ_M_RED: continue\n",
        "            xk, yk = xs_r[idx], ys_r[idx]\n",
        "            x0, x1 = int(xk.min()), int(xk.max()); y0, y1 = int(yk.min()), int(yk.max())\n",
        "            clusters_r.append(dict(idx=idx, xk=xk, yk=yk, x0=x0, x1=x1, y0=y0, y1=y1))\n",
        "    clusters_r.sort(key=lambda c: c['y0'])\n",
        "\n",
        "    # Nested red suppression (bbox)\n",
        "    kept, keep_rects = [], []\n",
        "    for c in clusters_r:\n",
        "        bbox = (c['x0'], c['y0'], c['x1'], c['y1'])\n",
        "        if any(rect_contains(R, bbox) for R in keep_rects): continue\n",
        "        kept.append(c); keep_rects.append(bbox)\n",
        "    clusters_r = kept\n",
        "\n",
        "    # Proportional occlusion rects\n",
        "    def compute_occ(c):\n",
        "        x0, x1, y0, y1 = c['x0'], c['x1'], c['y0'], c['y1']\n",
        "        bbox_w = (x1 - x0 + 1); bbox_h = (y1 - y0 + 1)\n",
        "        bbox_area_px = bbox_w * bbox_h\n",
        "        scale = np.sqrt(OCCLUSION_AREA_RATIO)\n",
        "        desired_w = max(bbox_w, int(np.ceil(scale * bbox_w)))\n",
        "        desired_h = max(bbox_h, int(np.ceil(scale * bbox_h)))\n",
        "        height_limit = H - y0\n",
        "        if x0 > center_x:\n",
        "            width_limit = W - x0\n",
        "            occ_h = min(desired_h, height_limit); occ_w = min(desired_w, width_limit)\n",
        "            target_area = int(np.ceil(OCCLUSION_AREA_RATIO * bbox_area_px))\n",
        "            area = occ_w * occ_h\n",
        "            if area < target_area and occ_h > 0:\n",
        "                if occ_w < width_limit:\n",
        "                    occ_w = min(width_limit, max(occ_w, int(np.ceil(target_area / occ_h)))); area = occ_w * occ_h\n",
        "                if area < target_area and occ_h < height_limit and occ_w > 0:\n",
        "                    occ_h = min(height_limit, max(occ_h, int(np.ceil(target_area / occ_w))))\n",
        "            occ_h = max(min(occ_h, height_limit), bbox_h); occ_w = min(occ_w, width_limit)\n",
        "            occ_x0 = x0; occ_x1 = min(W-1, x0 + occ_w - 1)\n",
        "        elif x1 < center_x:\n",
        "            width_limit = x1 + 1\n",
        "            occ_h = min(desired_h, height_limit); occ_w = min(desired_w, width_limit)\n",
        "            target_area = int(np.ceil(OCCLUSION_AREA_RATIO * bbox_area_px))\n",
        "            area = occ_w * occ_h\n",
        "            if area < target_area and occ_h > 0:\n",
        "                if occ_w < width_limit:\n",
        "                    occ_w = min(width_limit, max(occ_w, int(np.ceil(target_area / occ_h)))); area = occ_w * occ_h\n",
        "                if area < target_area and occ_h < height_limit and occ_w > 0:\n",
        "                    occ_h = min(height_limit, max(occ_h, int(np.ceil(target_area / occ_w))))\n",
        "            occ_h = max(min(occ_h, height_limit), bbox_h); occ_w = min(occ_w, width_limit)\n",
        "            occ_x1 = x1; occ_x0 = max(0, x1 - occ_w + 1)\n",
        "        else:\n",
        "            occ_x0, occ_x1 = x0, x1; occ_h = min(H - y0, desired_h)\n",
        "        occ_y0 = y0; occ_y1 = min(H-1, y0 + occ_h - 1)\n",
        "        c.update(dict(occ_x0=occ_x0, occ_x1=occ_x1, occ_y0=occ_y0, occ_y1=occ_y1))\n",
        "    for c in clusters_r: compute_occ(c)\n",
        "\n",
        "    # Nested suppression again with occ\n",
        "    kept2, keep_rects = [], []\n",
        "    for c in clusters_r:\n",
        "        bbox = (c['x0'], c['y0'], c['x1'], c['y1'])\n",
        "        occ  = (c['occ_x0'], c['occ_y0'], c['occ_x1'], c['occ_y1'])\n",
        "        if any(rect_contains(R, bbox) or rect_contains(R, occ) for R in keep_rects): continue\n",
        "        kept2.append(c); keep_rects += [bbox, occ]\n",
        "    clusters_r = kept2\n",
        "\n",
        "    # Masks where blue cannot exist as IDs\n",
        "    red_bbox_mask = np.zeros((H, W), dtype=bool)\n",
        "    occ_mask_pre  = np.zeros((H, W), dtype=bool)\n",
        "    for c in clusters_r:\n",
        "        red_bbox_mask[c['y0']:c['y1']+1, c['x0']:c['x1']+1] = True\n",
        "        ox0, oy0, ox1, oy1 = c['occ_x0'], c['occ_y0'], c['occ_x1'], c['occ_y1']\n",
        "        occ_mask_pre[oy0:oy1+1, ox0:ox1+1] = True\n",
        "\n",
        "    # Remember current red/occ regions for the NEXT frame’s ID protection exclusion\n",
        "    prev_red_bbox_mask = red_bbox_mask.copy()\n",
        "    prev_occ_mask      = occ_mask_pre.copy()\n",
        "\n",
        "    # ---------- Red→Blue radius suppression ----------\n",
        "    blue_mask = (score >= BLUE_SCORE_MIN) & (score <= BLUE_SCORE_MAX)\n",
        "    red_all_mask = (score >= CLUSTER_USE_VAL_RED)\n",
        "    red_influence = cv2.dilate(red_all_mask.astype(np.uint8), dil_kernel, 1).astype(bool)\n",
        "    suppressed_blue = blue_mask & red_influence\n",
        "    allowed_blue = blue_mask & ~suppressed_blue & ~red_bbox_mask & ~occ_mask_pre\n",
        "    annotated[suppressed_blue] = (0, 0, 0)\n",
        "\n",
        "    # ---------- Draw RED (fill then outlines) ----------\n",
        "    occluded_mask = np.zeros((H, W), dtype=bool)\n",
        "    new_prev_clusters_pixels = []\n",
        "    for c in clusters_r:\n",
        "        xk, yk = c['xk'], c['yk']\n",
        "        if xk.size and np.mean(occluded_mask[yk, xk]) >= OCCLUDED_SKIP_FRAC:\n",
        "            new_prev_clusters_pixels.append((yk.copy(), xk.copy()))\n",
        "            continue\n",
        "        x0, x1, y0, y1 = c['x0'], c['x1'], c['y0'], c['y1']\n",
        "        occ_x0, occ_x1, occ_y0, occ_y1 = c['occ_x0'], c['occ_x1'], c['occ_y0'], c['occ_y1']\n",
        "        annotated[occ_y0:occ_y1+1, occ_x0:occ_x1+1] = (0, 0, 0)\n",
        "        annotated[yk, xk] = COL_RED_OBJ_PT\n",
        "        occluded_mask[occ_y0:occ_y1+1, occ_x0:occ_x1+1] = True\n",
        "        new_prev_clusters_pixels.append((yk.copy(), xk.copy()))\n",
        "    prev_clusters_pixels = new_prev_clusters_pixels\n",
        "\n",
        "    with open(csv_path, 'a', newline='') as fcsv:\n",
        "        writer = csv.writer(fcsv)\n",
        "        for k, c in enumerate(clusters_r, start=1):\n",
        "            xk, yk = c['xk'], c['yk']\n",
        "            x0, x1, y0, y1 = c['x0'], c['x1'], c['y0'], c['y1']\n",
        "            occ_x0, occ_x1, occ_y0, occ_y1 = c['occ_x0'], c['occ_x1'], c['occ_y0'], c['occ_y1']\n",
        "            cx_px = int(np.round(xk.mean())); cy_px = int(np.round(yk.mean()))\n",
        "            cx_m = (cx_px - center_x) * SX; cy_m = Y_TOP_M + cy_px * SY\n",
        "            cv2.rectangle(annotated, (occ_x0, occ_y0), (occ_x1, occ_y1), COL_OCC_BOX, 1)\n",
        "            cv2.rectangle(annotated, (x0, y0), (x1, y1), COL_RED_BBOX, 1)\n",
        "            cv2.circle(annotated, (cx_px, cy_px), 3, (0, 255, 0), -1)\n",
        "            cv2.putText(annotated, f\"x={cx_m:.2f}m, y={cy_m:.2f}m\",\n",
        "                        (cx_px + 5, max(10, cy_px - 5)),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 255, 0), 1, cv2.LINE_AA)\n",
        "            writer.writerow([fname, k, f\"{cx_m:.3f}\", f\"{cy_m:.3f}\", cx_px, cy_px])\n",
        "\n",
        "    # ---------- BLUE detections ----------\n",
        "    ys_b, xs_b = np.where(allowed_blue)\n",
        "    detections = []\n",
        "    if xs_b.size:\n",
        "        x_m_b = (xs_b - center_x) * SX\n",
        "        y_m_b = Y_TOP_M + ys_b * SY\n",
        "        pts_b = np.c_[x_m_b, y_m_b]\n",
        "        db_b = DBSCAN(eps=EPS_M, min_samples=MIN_SAMPLES).fit(pts_b)\n",
        "        labels_b = db_b.labels_; uniq_b = [lab for lab in set(labels_b) if lab != -1]\n",
        "        for lab in uniq_b:\n",
        "            idx = np.where(labels_b == lab)[0]\n",
        "            if oriented_length_m(pts_b[idx]) < MIN_OBJ_M_BLUE: continue\n",
        "            xk, yk = xs_b[idx], ys_b[idx]\n",
        "            cx_px = int(np.round(xk.mean())); cy_px = int(np.round(yk.mean()))\n",
        "            cx_m = (cx_px - center_x) * SX; cy_m = Y_TOP_M + cy_px * SY\n",
        "            if red_bbox_mask[min(H-1, max(0, cy_px)), min(W-1, max(0, cx_px))]: continue\n",
        "            if occ_mask_pre[min(H-1, max(0, cy_px)), min(W-1, max(0, cx_px))]: continue\n",
        "            detections.append(dict(\n",
        "                cx_m=cx_m, cy_m=cy_m, cx_px=cx_px, cy_px=cy_px,\n",
        "                n=idx.size, extent_m=oriented_length_m(pts_b[idx])\n",
        "            ))\n",
        "\n",
        "    # ---------- In-frame consolidation ----------\n",
        "    if len(detections) > 1:\n",
        "        coords = np.array([[d['cx_m'], d['cy_m']] for d in detections], dtype=float)\n",
        "        diff = coords[:, None, :] - coords[None, :, :]\n",
        "        D = np.sqrt(np.sum(diff*diff, axis=2))\n",
        "        adjacency = (D <= CONSOLIDATION_RADIUS_M)\n",
        "        N = len(detections)\n",
        "        visited = np.zeros(N, dtype=bool)\n",
        "        keep_idx = []\n",
        "        for i in range(N):\n",
        "            if visited[i]: continue\n",
        "            stack = [i]; group = []\n",
        "            while stack:\n",
        "                j = stack.pop()\n",
        "                if visited[j]: continue\n",
        "                visited[j] = True\n",
        "                group.append(j)\n",
        "                for nb in np.where(adjacency[j])[0]:\n",
        "                    if not visited[nb]:\n",
        "                        stack.append(nb)\n",
        "            best = max(group, key=lambda g: (detections[g]['n'], detections[g]['extent_m'], -g))\n",
        "            keep_idx.append(best)\n",
        "        detections = [detections[k] for k in sorted(keep_idx)]\n",
        "\n",
        "    # ---------- Tracking ----------\n",
        "    matched_det_idx = set()\n",
        "    matched_track_keys = set()\n",
        "\n",
        "    if frame_idx >= WARMUP_FRAMES and (tracks or detections):\n",
        "        track_items = list(tracks.items())\n",
        "        pairs = []\n",
        "        for ti, (k, tr) in enumerate(track_items):\n",
        "            gap = max(1, frame_idx - tr['last_seen'])\n",
        "            for di, det in enumerate(detections):\n",
        "                d = float(np.hypot(det['cx_m'] - tr['centroid_m'][0], det['cy_m'] - tr['centroid_m'][1]))\n",
        "                if ASSOC_MIN_M <= d <= ASSOC_MAX_M:\n",
        "                    pairs.append((d, ti, di, gap))\n",
        "        pairs.sort(key=lambda x: x[0])\n",
        "\n",
        "        used_tracks = set()\n",
        "        used_dets = set()\n",
        "        for d, ti, di, gap in pairs:\n",
        "            if ti in used_tracks or di in used_dets:\n",
        "                continue\n",
        "            key, tr = track_items[ti]\n",
        "            used_tracks.add(ti); used_dets.add(di)\n",
        "            matched_det_idx.add(di); matched_track_keys.add(key)\n",
        "\n",
        "            prev_m = tr['centroid_m']\n",
        "            new_m  = np.array([detections[di]['cx_m'], detections[di]['cy_m']], dtype=float)\n",
        "\n",
        "            dt_sec = DT * max(1, gap)\n",
        "            vx = (new_m[0] - prev_m[0]) / dt_sec\n",
        "            vy = (new_m[1] - prev_m[1]) / dt_sec\n",
        "            disp = float(np.linalg.norm(new_m - prev_m))\n",
        "            speed = disp / dt_sec\n",
        "\n",
        "            tr.update({\n",
        "                'centroid_m': new_m,\n",
        "                'centroid_px': (detections[di]['cx_px'], detections[di]['cy_px']),\n",
        "                'last_seen': frame_idx,\n",
        "                'misses': 0,\n",
        "                'hits': tr['hits'] + 1,\n",
        "                'prev_m': prev_m,\n",
        "                'speed': speed,\n",
        "                'vel_mps': (vx, vy)\n",
        "            })\n",
        "            if not tr['confirmed'] and tr['hits'] >= CONFIRM_HITS:\n",
        "                tr['confirmed'] = True\n",
        "                tr['id'] = next_track_id\n",
        "                next_track_id += 1\n",
        "\n",
        "        # Unmatched tracks → miss\n",
        "        for key, tr in list(tracks.items()):\n",
        "            if key not in matched_track_keys:\n",
        "                tr['misses'] += 1\n",
        "                if tr['misses'] > MISS_TOL:\n",
        "                    del tracks[key]\n",
        "\n",
        "        # New tracks from unmatched detections\n",
        "        for di, det in enumerate(detections):\n",
        "            if di in matched_det_idx: continue\n",
        "            tracks[('t', internal_next_key)] = dict(\n",
        "                centroid_m=np.array([det['cx_m'], det['cy_m']], dtype=float),\n",
        "                centroid_px=(det['cx_px'], det['cy_px']),\n",
        "                last_seen=frame_idx,\n",
        "                hits=1, misses=0, confirmed=False,\n",
        "                id=None,\n",
        "                prev_m=np.array([det['cx_m'], det['cy_m']], dtype=float),\n",
        "                speed=0.0,\n",
        "                vel_mps=(0.0, 0.0)\n",
        "            )\n",
        "            internal_next_key += 1\n",
        "\n",
        "    else:\n",
        "        # Warm-up: seed tentative tracks (no rendering)\n",
        "        for det in detections:\n",
        "            tracks[('t', internal_next_key)] = dict(\n",
        "                centroid_m=np.array([det['cx_m'], det['cy_m']], dtype=float),\n",
        "                centroid_px=(det['cx_px'], det['cy_px']),\n",
        "                last_seen=frame_idx,\n",
        "                hits=1, misses=0, confirmed=False,\n",
        "                id=None,\n",
        "                prev_m=np.array([det['cx_m'], det['cy_m']], dtype=float),\n",
        "                speed=0.0,\n",
        "                vel_mps=(0.0, 0.0)\n",
        "            )\n",
        "            internal_next_key += 1\n",
        "\n",
        "    # --- Draw confirmed tracks + append to histories (NOT writing TestSet2 here) ---\n",
        "    with open(tracks_csv, 'a', newline='') as ft:\n",
        "        tw = csv.writer(ft)\n",
        "        for key, tr in tracks.items():\n",
        "            if not tr['confirmed'] or tr['last_seen'] != frame_idx:\n",
        "                continue\n",
        "\n",
        "            cx_px, cy_px = tr['centroid_px']\n",
        "            # Skip if centroid inside red bbox or occlusion\n",
        "            if red_bbox_mask[min(H-1, max(0, cy_px)), min(W-1, max(0, cx_px))]: continue\n",
        "            if occ_mask_pre[min(H-1, max(0, cy_px)), min(W-1, max(0, cx_px))]: continue\n",
        "\n",
        "            cx_m, cy_m = tr['centroid_m']\n",
        "            vx, vy = tr.get('vel_mps', (0.0, 0.0))\n",
        "            v = float(np.hypot(vx, vy))\n",
        "\n",
        "            # Dot\n",
        "            cv2.circle(annotated, (int(cx_px), int(cy_px)), 3, COL_PED, -1)\n",
        "\n",
        "            # Label block (ID + per-line metrics)\n",
        "            id_scale  = 0.60\n",
        "            num_scale = max(0.18, id_scale / 3.0)  # ~1/3 of ID size\n",
        "            base_x = int(cx_px) + 6\n",
        "            base_y = max(12, int(cy_px) - 6)\n",
        "            line_step = 12\n",
        "\n",
        "            cv2.putText(annotated, f\"ID {tr['id']}\",\n",
        "                        (base_x, base_y),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, id_scale, COL_PED_TEXT, 1, cv2.LINE_AA)\n",
        "            cv2.putText(annotated, f\"x={cx_m:.2f} m\",\n",
        "                        (base_x, base_y + 1*line_step),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, num_scale, COL_PED_TEXT, 1, cv2.LINE_AA)\n",
        "            cv2.putText(annotated, f\"y={cy_m:.2f} m\",\n",
        "                        (base_x, base_y + 2*line_step),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, num_scale, COL_PED_TEXT, 1, cv2.LINE_AA)\n",
        "            cv2.putText(annotated, f\"vx={vx:+.2f} m/s\",\n",
        "                        (base_x, base_y + 3*line_step),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, num_scale, COLPED_TEXT:=COL_PED_TEXT, 1, cv2.LINE_AA)  # small trick to keep color const\n",
        "            cv2.putText(annotated, f\"vy={vy:+.2f} m/s\",\n",
        "                        (base_x, base_y + 4*line_step),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, num_scale, COL_PED_TEXT, 1, cv2.LINE_AA)\n",
        "            cv2.putText(annotated, f\"v={v:.2f} m/s\",\n",
        "                        (base_x, base_y + 5*line_step),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, num_scale, COL_PED_TEXT, 1, cv2.LINE_AA)\n",
        "\n",
        "            # Legacy tracker csv (kept)\n",
        "            state = ''\n",
        "            tw.writerow([fname, tr['id'], state, f\"{cx_m:.3f}\", f\"{cy_m:.3f}\",\n",
        "                         int(cx_px), int(cy_px), f\"{tr['speed']:.3f}\"])\n",
        "\n",
        "            # Append to in-memory history for TestSet2\n",
        "            t_ms = int(round((frame_idx + 1) * DT * 1000))  # 250, 500, 750, ...\n",
        "            records_by_id[tr['id']].append(\n",
        "                (frame_idx, t_ms, float(cx_m), float(cy_m), float(vx), float(vy), float(v))\n",
        "            )\n",
        "\n",
        "    # Save frame\n",
        "    out = os.path.join(frames_dir, f\"{os.path.splitext(fname)[0]}_occ.png\")\n",
        "    cv2.imwrite(out, annotated)\n",
        "\n",
        "print(f\"\\nSaved {len(os.listdir(frames_dir))} frames to {frames_dir}\")\n",
        "print(f\"Centroids CSV → {csv_path}\")\n",
        "print(f\"Pedestrian tracks CSV → {tracks_csv}\")\n",
        "\n",
        "# ---------- Build TestSet2.csv at the end (filter IDs with >=5 frames; x+1/y+1 need exact t+1.0s row) ----------\n",
        "with open(testset1_csv, 'w', newline='') as fts1:\n",
        "    w2 = csv.writer(fts1)\n",
        "    w2.writerow(['t_ms','id','x','y','vx','vy','v','x_plus_1','y_plus_1'])\n",
        "\n",
        "    for tid, recs in records_by_id.items():\n",
        "        # Only include IDs with at least 5 valid frames\n",
        "        if len(recs) < 5:\n",
        "            continue\n",
        "        # Map frame_idx -> (x,y) to fetch exact +4 frames\n",
        "        by_frame = {fi: (x, y) for (fi, _t, x, y, _vx, _vy, _v) in recs}\n",
        "        # Emit rows\n",
        "        for (fi, t_ms, x, y, vx, vy, v) in recs:\n",
        "            target_fi = fi + 4  # +1.0 s at 4 Hz\n",
        "            if target_fi in by_frame:\n",
        "                x1, y1 = by_frame[target_fi]\n",
        "                x1s, y1s = f\"{x1:.6f}\", f\"{y1:.6f}\"\n",
        "            else:\n",
        "                x1s, y1s = \"NaN\", \"NaN\"\n",
        "            w2.writerow([t_ms, tid,\n",
        "                         f\"{x:.6f}\", f\"{y:.6f}\",\n",
        "                         f\"{vx:.6f}\", f\"{vy:.6f}\", f\"{v:.6f}\",\n",
        "                         x1s, y1s])\n",
        "\n",
        "print(f\"TestSet1 CSV → {testset1_csv}\")\n",
        "\n",
        "# ---------- Build MP4 @ 4 Hz ----------\n",
        "fps = 4\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "writer = cv2.VideoWriter(video_path, fourcc, fps, (W, H), True)\n",
        "for fname in pngs:\n",
        "    img_path = os.path.join(frames_dir, f\"{os.path.splitext(fname)[0]}_occ.png\")\n",
        "    frame = cv2.imread(img_path)\n",
        "    if frame is not None:\n",
        "        writer.write(frame)\n",
        "writer.release()\n",
        "\n",
        "print(f\"\\nWrote video → {video_path} at {fps} fps ({W}x{H}).\")\n",
        "display(HTML(f'<video controls src=\"{video_path}\" width=\"640\"></video>'))\n",
        "files.download(video_path)\n",
        "files.download(csv_path)\n",
        "files.download(tracks_csv)\n",
        "files.download(testset1_csv)\n",
        "\n",
        "# ---------- Zip all final annotated frames ----------\n",
        "zip_path = '/content/annotated_frames.zip'\n",
        "with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zf:\n",
        "    for fn in sorted(os.listdir(frames_dir)):\n",
        "        if fn.endswith('_occ.png'):\n",
        "            zf.write(os.path.join(frames_dir, fn), arcname=fn)\n",
        "\n",
        "# NEW: copy the ZIP to Google Drive (keeps everything else the same)\n",
        "drive_zip_path = '/content/drive/MyDrive/annotated_frames.zip'\n",
        "shutil.copy2(zip_path, drive_zip_path)\n",
        "print(f\"Saved annotated frames ZIP to Drive → {drive_zip_path}\")\n",
        "\n",
        "files.download(zip_path)\n"
      ]
    }
  ]
}