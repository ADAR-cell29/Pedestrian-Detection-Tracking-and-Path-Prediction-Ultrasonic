{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZYiixi8dRx4",
        "outputId": "7de0981c-0b69-43b3-80a7-894aa98b7472"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Epoch 01 | TrainLoss 0.517970 | ValLoss 0.389923 | ValRMSE_1s 1.936\n",
            "Epoch 02 | TrainLoss 0.283740 | ValLoss 0.140564 | ValRMSE_1s 1.220\n",
            "Epoch 03 | TrainLoss 0.117938 | ValLoss 0.085253 | ValRMSE_1s 0.990\n",
            "Epoch 04 | TrainLoss 0.085434 | ValLoss 0.067121 | ValRMSE_1s 0.871\n",
            "Epoch 05 | TrainLoss 0.042303 | ValLoss 0.024390 | ValRMSE_1s 0.510\n",
            "Epoch 06 | TrainLoss 0.021193 | ValLoss 0.015934 | ValRMSE_1s 0.409\n",
            "Epoch 07 | TrainLoss 0.017104 | ValLoss 0.013733 | ValRMSE_1s 0.378\n",
            "Epoch 08 | TrainLoss 0.015116 | ValLoss 0.012696 | ValRMSE_1s 0.363\n",
            "Epoch 09 | TrainLoss 0.014014 | ValLoss 0.012427 | ValRMSE_1s 0.358\n",
            "Epoch 10 | TrainLoss 0.013308 | ValLoss 0.011268 | ValRMSE_1s 0.342\n",
            "Epoch 11 | TrainLoss 0.012633 | ValLoss 0.010999 | ValRMSE_1s 0.338\n",
            "Epoch 12 | TrainLoss 0.012119 | ValLoss 0.010422 | ValRMSE_1s 0.328\n",
            "Epoch 13 | TrainLoss 0.011745 | ValLoss 0.010310 | ValRMSE_1s 0.326\n",
            "Epoch 14 | TrainLoss 0.011528 | ValLoss 0.009872 | ValRMSE_1s 0.319\n",
            "Epoch 15 | TrainLoss 0.011174 | ValLoss 0.009783 | ValRMSE_1s 0.317\n",
            "Epoch 16 | TrainLoss 0.011158 | ValLoss 0.009678 | ValRMSE_1s 0.317\n",
            "Epoch 17 | TrainLoss 0.010590 | ValLoss 0.009096 | ValRMSE_1s 0.306\n",
            "Generating +1 s sparse plots for 221 pedestrians…\n",
            "Created ZIP → val_tracks_1s_horizons.zip\n"
          ]
        }
      ],
      "source": [
        "# =========================\n",
        "# CONFIG\n",
        "# =========================\n",
        "CONFIG = {\n",
        "    \"train_csv\": \"TrainingSet.csv\",\n",
        "    \"val_csv\":   \"ValidationSet.csv\",\n",
        "\n",
        "    # Normalization mode: \"physics\" or \"zscore\"\n",
        "    \"NORM_MODE\": \"physics\",\n",
        "\n",
        "    # Model hyperparameters\n",
        "    \"INPUT_DIM\": 4,        # (x, y, vx, vy)\n",
        "    \"HIDDEN_SIZE\": 80,\n",
        "    \"NUM_LAYERS\": 4,\n",
        "    \"DROPOUT\": 0.1,\n",
        "\n",
        "    # Optimization\n",
        "    \"BATCH_SIZE\": 32,\n",
        "    \"NUM_EPOCHS\": 17,\n",
        "    \"LR\": 1e-3,\n",
        "    \"WEIGHT_DECAY\": 1e-5,\n",
        "    \"GRAD_CLIP\": 1.0,\n",
        "\n",
        "    # Early stopping\n",
        "    \"EARLY_STOP_PATIENCE\": 5,\n",
        "    \"MIN_DELTA\": 1e-5,\n",
        "\n",
        "    # LR scheduler\n",
        "    \"SCHEDULER_FACTOR\": 0.5,\n",
        "    \"SCHEDULER_PATIENCE\": 2,\n",
        "\n",
        "    # Random seed\n",
        "    \"SEED\": 42,\n",
        "\n",
        "    # Device preference\n",
        "    \"FORCE_CPU\": False,\n",
        "\n",
        "    # Saving\n",
        "    \"SAVE_PREFIX\": \"lstm_fullseq_1s\",\n",
        "}\n",
        "\n",
        "# =========================\n",
        "# Imports & Setup\n",
        "# =========================\n",
        "import os, shutil, zipfile, random, math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.patches import Circle\n",
        "\n",
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "set_seed(CONFIG[\"SEED\"])\n",
        "\n",
        "device = torch.device(\"cpu\" if CONFIG[\"FORCE_CPU\"] or not torch.cuda.is_available() else \"cuda\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "DT = 1.0 / 30.0\n",
        "\n",
        "# =========================\n",
        "# Load & Prepare Data\n",
        "# =========================\n",
        "def load_and_prepare(csv_path):\n",
        "    df = pd.read_csv(csv_path)\n",
        "    if \"fut1_x\" in df.columns:\n",
        "        df = df.rename(columns={\"fut1_x\":\"future1_x\",\"fut1_y\":\"future1_y\"})\n",
        "    needed = {\"time_s\",\"ped_id\",\"x\",\"y\",\"vx\",\"vy\",\"future1_x\",\"future1_y\"}\n",
        "    missing = needed - set(df.columns)\n",
        "    if missing:\n",
        "        raise ValueError(f\"{csv_path} missing columns: {missing}\")\n",
        "    df = df.sort_values([\"ped_id\",\"time_s\"]).reset_index(drop=True)\n",
        "    df = df.dropna(subset=[\"future1_x\",\"future1_y\"]).reset_index(drop=True)\n",
        "    return df\n",
        "\n",
        "train_df = load_and_prepare(CONFIG[\"train_csv\"])\n",
        "val_df   = load_and_prepare(CONFIG[\"val_csv\"])\n",
        "\n",
        "# =========================\n",
        "# Normalizer\n",
        "# =========================\n",
        "class Normalizer:\n",
        "    def __init__(self, mode=\"physics\"):\n",
        "        self.mode = mode\n",
        "        self.x_scale = 3.0\n",
        "        self.y_min   = 0.1\n",
        "        self.y_range = 3.6 - 0.1\n",
        "        self.v_scale = 2.0\n",
        "        self.stats   = {}\n",
        "    def fit_zscore(self, df):\n",
        "        for c in [\"x\",\"y\",\"vx\",\"vy\",\"future1_x\",\"future1_y\"]:\n",
        "            m, s = df[c].mean(), df[c].std()+1e-8\n",
        "            self.stats[c] = {\"mean\":m,\"std\":s}\n",
        "    def transform_rows(self, df):\n",
        "        if self.mode==\"physics\":\n",
        "            df[\"x_n\"]  = df[\"x\"]/self.x_scale\n",
        "            df[\"y_n\"]  = (df[\"y\"]-self.y_min)/self.y_range\n",
        "            df[\"vx_n\"] = df[\"vx\"]/self.v_scale\n",
        "            df[\"vy_n\"] = df[\"vy\"]/self.v_scale\n",
        "            df[\"f1x_n\"] = df[\"future1_x\"]/self.x_scale\n",
        "            df[\"f1y_n\"] = (df[\"future1_y\"]-self.y_min)/self.y_range\n",
        "        else:\n",
        "            for base,new in [(\"x\",\"x_n\"),(\"y\",\"y_n\"),(\"vx\",\"vx_n\"),(\"vy\",\"vy_n\"),\n",
        "                             (\"future1_x\",\"f1x_n\"),(\"future1_y\",\"f1y_n\")]:\n",
        "                df[new] = (df[base]-self.stats[base][\"mean\"])/self.stats[base][\"std\"]\n",
        "        return df\n",
        "    def inverse_pos(self,xn,yn):\n",
        "        if self.mode==\"physics\":\n",
        "            return xn*self.x_scale, yn*self.y_range+self.y_min\n",
        "        s_x,s_y = self.stats[\"future1_x\"][\"std\"],self.stats[\"future1_y\"][\"std\"]\n",
        "        m_x,m_y = self.stats[\"future1_x\"][\"mean\"],self.stats[\"future1_y\"][\"mean\"]\n",
        "        return xn*s_x+m_x, yn*s_y+m_y\n",
        "\n",
        "normalizer = Normalizer(CONFIG[\"NORM_MODE\"])\n",
        "if CONFIG[\"NORM_MODE\"]==\"zscore\":\n",
        "    normalizer.fit_zscore(train_df)\n",
        "train_df = normalizer.transform_rows(train_df)\n",
        "val_df   = normalizer.transform_rows(val_df)\n",
        "\n",
        "# =========================\n",
        "# Build Sequences\n",
        "# =========================\n",
        "def build_seqs(df):\n",
        "    seqs=[]\n",
        "    for pid,g in df.groupby(\"ped_id\"):\n",
        "        g=g.sort_values(\"time_s\").reset_index(drop=True)\n",
        "        if len(g)<1: continue\n",
        "        feats = g[[\"x_n\",\"y_n\",\"vx_n\",\"vy_n\"]].values.astype(np.float32)\n",
        "        targs = g[[\"f1x_n\",\"f1y_n\"]].values.astype(np.float32)\n",
        "        seqs.append((feats,targs,pid))\n",
        "    return seqs\n",
        "\n",
        "train_seqs = build_seqs(train_df)\n",
        "val_seqs   = build_seqs(val_df)\n",
        "\n",
        "# =========================\n",
        "# Dataset & Collate\n",
        "# =========================\n",
        "class PedDataset(Dataset):\n",
        "    def __init__(self,seqs): self.seqs=seqs\n",
        "    def __len__(self): return len(self.seqs)\n",
        "    def __getitem__(self,i):\n",
        "        f,t,p = self.seqs[i]\n",
        "        return torch.from_numpy(f),torch.from_numpy(t),p\n",
        "\n",
        "def collate(batch):\n",
        "    feats,targs,pids = zip(*batch)\n",
        "    L = torch.tensor([f.shape[0] for f in feats],dtype=torch.long)\n",
        "    fp = pad_sequence(feats, batch_first=True)\n",
        "    tp = pad_sequence(targs, batch_first=True)\n",
        "    m = torch.zeros(fp.size(0),fp.size(1))\n",
        "    for i,l in enumerate(L): m[i,:l]=1\n",
        "    return fp,tp,m,L,pids\n",
        "\n",
        "train_loader = DataLoader(PedDataset(train_seqs),batch_size=CONFIG[\"BATCH_SIZE\"],\n",
        "                          shuffle=True,collate_fn=collate)\n",
        "val_loader   = DataLoader(PedDataset(val_seqs),batch_size=CONFIG[\"BATCH_SIZE\"],\n",
        "                          shuffle=False,collate_fn=collate)\n",
        "\n",
        "# =========================\n",
        "# Model\n",
        "# =========================\n",
        "class LSTMNet(nn.Module):\n",
        "    def __init__(self,in_dim,hidden,layers,drop):\n",
        "        super().__init__()\n",
        "        self.lstm = nn.LSTM(in_dim,hidden,layers,\n",
        "                            batch_first=True,\n",
        "                            dropout=drop if layers>1 else 0.0)\n",
        "        self.head = nn.Linear(hidden,2)\n",
        "    def forward(self,x,lengths):\n",
        "        packed = nn.utils.rnn.pack_padded_sequence(x,lengths.cpu(),\n",
        "                                                    batch_first=True,\n",
        "                                                    enforce_sorted=False)\n",
        "        out,_ = self.lstm(packed)\n",
        "        out,_ = nn.utils.rnn.pad_packed_sequence(out,batch_first=True)\n",
        "        return self.head(out)\n",
        "\n",
        "model = LSTMNet(CONFIG[\"INPUT_DIM\"],\n",
        "                CONFIG[\"HIDDEN_SIZE\"],\n",
        "                CONFIG[\"NUM_LAYERS\"],\n",
        "                CONFIG[\"DROPOUT\"]).to(device)\n",
        "\n",
        "# =========================\n",
        "# Loss & Metric\n",
        "# =========================\n",
        "def masked_mse(p,t,m):\n",
        "    d=(p-t)**2\n",
        "    return (d.sum(-1)*m).sum()/m.sum().clamp_min(1.0)\n",
        "\n",
        "def rmse_1s(p,t,m):\n",
        "    with torch.no_grad():\n",
        "        valid=(m>0)\n",
        "        px,py = p[valid][:,0],p[valid][:,1]\n",
        "        tx,ty = t[valid][:,0],t[valid][:,1]\n",
        "        x_p,y_p = normalizer.inverse_pos(px.cpu().numpy(),py.cpu().numpy())\n",
        "        x_t,y_t = normalizer.inverse_pos(tx.cpu().numpy(),ty.cpu().numpy())\n",
        "        return float(np.sqrt(((x_p-x_t)**2+(y_p-y_t)**2).mean()))\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(),\n",
        "                             lr=CONFIG[\"LR\"],\n",
        "                             weight_decay=CONFIG[\"WEIGHT_DECAY\"])\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer,mode=\"min\",\n",
        "    factor=CONFIG[\"SCHEDULER_FACTOR\"],\n",
        "    patience=CONFIG[\"SCHEDULER_PATIENCE\"]\n",
        ")\n",
        "\n",
        "best_loss=float(\"inf\");no_imp=0;best_state=None\n",
        "\n",
        "# =========================\n",
        "# Training Loop\n",
        "# =========================\n",
        "for epoch in range(1,CONFIG[\"NUM_EPOCHS\"]+1):\n",
        "    model.train()\n",
        "    tloss,tn=0,0\n",
        "    for f,t,m,L,_ in train_loader:\n",
        "        f,t,m = f.to(device),t.to(device),m.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        pred = model(f,L)\n",
        "        loss = masked_mse(pred,t,m)\n",
        "        loss.backward()\n",
        "        nn.utils.clip_grad_norm_(model.parameters(),CONFIG[\"GRAD_CLIP\"])\n",
        "        optimizer.step()\n",
        "        tloss += loss.item()*m.sum().item()\n",
        "        tn    += m.sum().item()\n",
        "    train_loss = tloss/tn\n",
        "\n",
        "    model.eval()\n",
        "    vloss,vn,v_rmse=0,0,0\n",
        "    with torch.no_grad():\n",
        "        for f,t,m,L,_ in val_loader:\n",
        "            f,t,m = f.to(device),t.to(device),m.to(device)\n",
        "            pred = model(f,L)\n",
        "            vloss += masked_mse(pred,t,m).item()*m.sum().item()\n",
        "            vn    += m.sum().item()\n",
        "            v_rmse += rmse_1s(pred,t,m)*f.size(0)\n",
        "    val_loss = vloss/vn\n",
        "    val_rmse = v_rmse/len(val_loader.dataset)\n",
        "    scheduler.step(val_loss)\n",
        "\n",
        "    print(f\"Epoch {epoch:02d} | TrainLoss {train_loss:.6f} | \"\n",
        "          f\"ValLoss {val_loss:.6f} | ValRMSE_1s {val_rmse:.3f}\")\n",
        "\n",
        "    if val_loss+CONFIG[\"MIN_DELTA\"]<best_loss:\n",
        "        best_loss=val_loss; no_imp=0\n",
        "        best_state={\"model\":model.state_dict(),\n",
        "                    \"opt\":optimizer.state_dict(),\n",
        "                    \"epoch\":epoch,\"loss\":best_loss}\n",
        "    else:\n",
        "        no_imp+=1\n",
        "        if no_imp>=CONFIG[\"EARLY_STOP_PATIENCE\"]:\n",
        "            print(\"Early stopping.\")\n",
        "            break\n",
        "\n",
        "model.load_state_dict(best_state[\"model\"])\n",
        "torch.save(best_state,f\"{CONFIG['SAVE_PREFIX']}_model.pt\")\n",
        "\n",
        "# =========================\n",
        "# Full‑Track Visualization (+1 s horizon only)\n",
        "# =========================\n",
        "OUTPUT_DIR         = \"val_tracks_1s_horizons\"\n",
        "ZIP_NAME           = \"val_tracks_1s_horizons.zip\"\n",
        "MAKE_ZIP           = True\n",
        "CLEAR_OUTPUT_FIRST = True\n",
        "SHOW_FIGS          = False\n",
        "\n",
        "ANCHOR_PERIOD_S     = 1.0   # show prediction every 1 s\n",
        "ANCHOR_START_OFFSET = 0.0   # start at t0\n",
        "\n",
        "MARKER_PATH   = 2\n",
        "MARKER_TRUE1  = 6\n",
        "MARKER_PRED1  = 6\n",
        "SHOW_SEG_LINES = True\n",
        "TOL_RADIUS = 0.3  # meters\n",
        "\n",
        "if CLEAR_OUTPUT_FIRST and os.path.isdir(OUTPUT_DIR):\n",
        "    shutil.rmtree(OUTPUT_DIR)\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "def build_feat_norm_track(df_slice):\n",
        "    if normalizer.mode == \"physics\":\n",
        "        return np.stack([\n",
        "            df_slice.x / normalizer.x_scale,\n",
        "            (df_slice.y - normalizer.y_min) / normalizer.y_range,\n",
        "            df_slice.vx / normalizer.v_scale,\n",
        "            df_slice.vy / normalizer.v_scale\n",
        "        ], axis=-1).astype(np.float32)\n",
        "    stats = normalizer.stats\n",
        "    return np.stack([\n",
        "        (df_slice.x - stats['x']['mean'])/stats['x']['std'],\n",
        "        (df_slice.y - stats['y']['mean'])/stats['y']['std'],\n",
        "        (df_slice.vx - stats['vx']['mean'])/stats['vx']['std'],\n",
        "        (df_slice.vy - stats['vy']['mean'])/stats['vy']['std'],\n",
        "    ], axis=-1).astype(np.float32)\n",
        "\n",
        "def predict_track_1s(track_df):\n",
        "    feat_norm = build_feat_norm_track(track_df)\n",
        "    feats_t = torch.from_numpy(feat_norm).unsqueeze(0).to(device)\n",
        "    lengths = torch.tensor([feat_norm.shape[0]])\n",
        "    with torch.no_grad():\n",
        "        preds = model(feats_t, lengths)[0].cpu().numpy()\n",
        "    p1x_n, p1y_n = preds[:,0], preds[:,1]\n",
        "    p1x, p1y = normalizer.inverse_pos(p1x_n, p1y_n)\n",
        "    t1x = track_df.future1_x.values\n",
        "    t1y = track_df.future1_y.values\n",
        "    return track_df.time_s.values, track_df.x.values, track_df.y.values, t1x, t1y, p1x, p1y\n",
        "\n",
        "def compute_anchor_mask(times, dt_frame, period, start):\n",
        "    t0 = times[0]\n",
        "    tol = dt_frame/2\n",
        "    mask = np.zeros_like(times, dtype=bool)\n",
        "    for i, t in enumerate(times):\n",
        "        if t + tol < t0 + start:\n",
        "            continue\n",
        "        k = round((t - (t0 + start)) / period)\n",
        "        target = t0 + start + k * period\n",
        "        if abs(t - target) <= tol:\n",
        "            mask[i] = True\n",
        "    return mask\n",
        "\n",
        "def plot_and_save_1s(pid, df, out_path):\n",
        "    times, cx, cy, tx, ty, px, py = predict_track_1s(df)\n",
        "    anchor_mask = compute_anchor_mask(times, DT, ANCHOR_PERIOD_S, ANCHOR_START_OFFSET)\n",
        "    anchors = np.where(anchor_mask)[0]\n",
        "\n",
        "    plt.figure(figsize=(7,7))\n",
        "    ax = plt.gca()\n",
        "\n",
        "    # Draw the pedestrian path\n",
        "    ax.plot(cx, cy, '-o', ms=MARKER_PATH, color='black', alpha=0.8, label='Path')\n",
        "\n",
        "    # Plot predictions, true positions, and tolerance zones\n",
        "    for i in anchors:\n",
        "        # Green transparent circle around true point (0.3 m radius)\n",
        "        circle = Circle((tx[i], ty[i]), TOL_RADIUS, color='green', alpha=0.2)\n",
        "        ax.add_patch(circle)\n",
        "\n",
        "        # True point and predicted point\n",
        "        ax.plot(tx[i], ty[i], 'o', ms=MARKER_TRUE1, color='green', alpha=0.9)\n",
        "        ax.plot(px[i], py[i], 'x', ms=MARKER_PRED1, color='red')\n",
        "\n",
        "        # Optional connecting lines\n",
        "        if SHOW_SEG_LINES:\n",
        "            ax.plot([cx[i], px[i]], [cy[i], py[i]], color='red', alpha=0.3, lw=0.8)\n",
        "            ax.plot([cx[i], tx[i]], [cy[i], ty[i]], color='green', alpha=0.3, lw=0.8)\n",
        "\n",
        "    # Start and end markers\n",
        "    ax.plot(cx[0], cy[0], '*', ms=12, color='blue', label='Start')\n",
        "    ax.plot(cx[-1], cy[-1], '*', ms=12, color='orange', label='End')\n",
        "\n",
        "    # Legend including the circle\n",
        "    legend_elements = [\n",
        "        plt.Line2D([0], [0], color='black', marker='o', linestyle='-', markersize=MARKER_PATH, label='Path'),\n",
        "        plt.Line2D([0], [0], color='green', marker='o', linestyle='None', markersize=MARKER_TRUE1, label='True +1 s'),\n",
        "        plt.Line2D([0], [0], color='red', marker='x', linestyle='None', markersize=MARKER_PRED1, label='Pred +1 s'),\n",
        "        plt.Line2D([0], [0], color='blue', marker='*', linestyle='None', markersize=12, label='Start'),\n",
        "        plt.Line2D([0], [0], color='orange', marker='*', linestyle='None', markersize=12, label='End'),\n",
        "        plt.Line2D([0], [0], marker='o', color='green', markersize=15, alpha=0.2, linestyle='None', label='0.3 m Zone')\n",
        "    ]\n",
        "    ax.legend(handles=legend_elements, loc='best')\n",
        "\n",
        "    # Formatting\n",
        "    ax.set_title(f\"Ped {pid}: +1 s horizon every {ANCHOR_PERIOD_S:.1f}s\")\n",
        "    ax.set_xlabel(\"X (m)\")\n",
        "    ax.set_ylabel(\"Y (m)\")\n",
        "    ax.set_xlim(-3, 3)\n",
        "    ax.set_ylim(0.1, 3.6)\n",
        "    ax.grid(True)\n",
        "\n",
        "    if SHOW_FIGS:\n",
        "        plt.show()\n",
        "    else:\n",
        "        plt.savefig(out_path, dpi=150, bbox_inches='tight')\n",
        "        plt.close()\n",
        "\n",
        "# Generate images\n",
        "groups = val_df.groupby('ped_id')\n",
        "print(f\"Generating +1 s sparse plots for {len(groups)} pedestrians…\")\n",
        "for pid, g in groups:\n",
        "    g = g.sort_values('time_s').reset_index(drop=True)\n",
        "    fn = f\"ped_{pid:03d}.png\"\n",
        "    plot_and_save_1s(pid, g, os.path.join(OUTPUT_DIR, fn))\n",
        "\n",
        "# Zip files if needed\n",
        "if MAKE_ZIP:\n",
        "    with zipfile.ZipFile(ZIP_NAME, 'w', zipfile.ZIP_DEFLATED) as zf:\n",
        "        for fn in sorted(os.listdir(OUTPUT_DIR)):\n",
        "            if fn.endswith('.png'):\n",
        "                zf.write(os.path.join(OUTPUT_DIR, fn), arcname=fn)\n",
        "    print(f\"Created ZIP → {ZIP_NAME}\")\n"
      ]
    }
  ]
}